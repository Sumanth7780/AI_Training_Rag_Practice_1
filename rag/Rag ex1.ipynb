{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import PyPDF2\n",
    "\n",
    "#Function to Load pdf documents\n",
    "def load_pdf_documents(directory):\n",
    "    documents =[]\n",
    "    file_names =[]\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('.pdf'):\n",
    "            file_path=os.path.join(directory,filename)\n",
    "            with open(file_path,'rb') as file:\n",
    "                reader=PyPDF2.PdfReader(file)\n",
    "                text=''\n",
    "                for page in range(len(reader.pages)):\n",
    "                    text += reader.pages[page].extract_text()\n",
    "                documents.append(text)\n",
    "                file_names.append(filename)\n",
    "    return documents, file_names\n",
    "\n",
    "pdf_directory = r\"D:\\brochures\" \n",
    "documents, file_names= load_pdf_documents(pdf_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Intialize the Vectorization and fit the documents\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer= TfidfVectorizer()\n",
    "doc_vectors =vectorizer.fit_transform(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize the Query, Compute Cosine Similarity between the query vector and document vector, Fetch the index of most relevant document vector\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "def retrieve_relevant_document(query,doc_vectors,vectorizer,documents,file_names):\n",
    "    #Vectorizing the query\n",
    "    query_vector = vectorizer.transform([query])\n",
    "    #Compute Cosine Similarities \n",
    "    similarities =cosine_similarity(query_vector,doc_vectors).flatten()\n",
    "    #Get the index of the most similar document\n",
    "    most_similar_doc_index =np.argmax(similarities)\n",
    "    return documents[most_similar_doc_index], file_names[most_similar_doc_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "c:\\Users\\DELL\\anaconda3\\Lib\\site-packages\\transformers\\generation\\utils.py:1262: UserWarning: Input length of input_ids is 295, but `max_length` is set to 50. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved Document:  \n",
      "  \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "Wherever you want to go, Margie’s Travel can get you there ! \n",
      "Margie’s Travel is a world -leading travel agency, combining international reach with local \n",
      "expertise. Just tell us wher....\n",
      "\n",
      "Document Source:Margies Travel Company Info.pdf\n",
      "\n",
      "Generated Response: \n",
      "  \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "Wherever you want to go, Margie’s Travel can get you there! \n",
      "Margie’s Travel is a world -leading travel agency, combining international reach with local \n",
      "expertise. Just tell us where you want to go, and we can arrange:  \n",
      "• Flights  \n",
      "• Accommodation  \n",
      "• Transfers  • Visas  \n",
      "• Currency Exchange  \n",
      "• Excursions  \n",
      " \n",
      "Where We Go  \n",
      "While we can arrange travel to anywhere  \n",
      "worldwide, we specialize in trips to:  \n",
      "• Dubai  \n",
      "• Las Vegas  \n",
      "• London  \n",
      "• New York  \n",
      "• San Francisco  Who We Are  \n",
      "Margie’s Travel employs some of the \n",
      "best travel experts in the world. Our \n",
      "leadership team consists of:  \n",
      "• Marjorie  Long  (CEO)  \n",
      "• Logan  Reid  (CFO)  \n",
      "• Emma  Luffman  (CTO)  \n",
      "• Deepak  Nadar  (Strategic Director)  \n",
      " \n",
      "To learn more about us, visit  our website at  www.margiestrave l.com  \n",
      " [SEP] Lets go to Africa \n"
     ]
    }
   ],
   "source": [
    "#Load Pre trained model and tokenizer\n",
    "\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "\n",
    "tokenizer =GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model=GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "\n",
    "def generate_response(query,context):\n",
    "#Combine the context and query into a single input for the model\n",
    "    input_text = f\"{context} [SEP] {query}\"\n",
    "    input_ids =tokenizer.encode(input_text, return_tensors='pt')\n",
    "\n",
    "#Generate the output\n",
    "    output=model.generate(input_ids, max_length=50, num_return_sequences=1)\n",
    "    response= tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    return response\n",
    "\n",
    "#RAG Pipeline\n",
    "\n",
    "def rag_pipeline(query):\n",
    "    #Step 1: Retrieving the most relevant document\n",
    "    context, file_name = retrieve_relevant_document(query, doc_vectors,vectorizer, documents, file_names)\n",
    "    print(f\"Retrieved Document: {context[:200]}....\\n\")  # print first 200 characters of the document\n",
    "    print(f\"Document Source:{file_name}\\n\")\n",
    "\n",
    "    # Step 2: Generate a response using the retrieved document as context\n",
    "    response=generate_response(query,context)\n",
    "    return response\n",
    "\n",
    "query =input(\"Hi. I am your Travel assistant. How can I help you?\")\n",
    "response= rag_pipeline(query)\n",
    "print(f\"Generated Response:{response}\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
