{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz \n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import VectorParams, Distance, PointStruct\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import pipeline, GPT2LMHeadModel, GPT2Tokenizer\n",
    "import os\n",
    "import uuid   #To generate UUIDs for the documents\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to extract text from PDF Files\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    text=\"\"\n",
    "    doc =fitz.open(pdf_path)\n",
    "    for page in doc:\n",
    "        text+=page.get_text()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialization of Qdrant Client\n",
    "qdrant=QdrantClient(\":memory:\") # you can specify the path to a storage as well\n",
    "\n",
    "#Define the collection name\n",
    "collection_name=\"document_embeddings\"\n",
    "\n",
    "#Define the embedding dimensionality \n",
    "embedding_dim=384\n",
    "\n",
    "#create a collection in Qdrant \n",
    "qdrant.create_collection(\n",
    "    collection_name=collection_name,vectors_config=VectorParams(size=embedding_dim,distance=Distance.COSINE),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load a model for generating embeddings\n",
    "embedder=SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "#Path of the documents\n",
    "pdf_dir=r\"D:\\\\intership\\\\Training\\\\assigment\\\\rag\\\\brochures\"    #the path where the documents are stored\n",
    "\n",
    "#Iteration over PDF files and extract text\n",
    "for pdf_file in os.listdir(pdf_dir):\n",
    "    if pdf_file.endswith(\".pdf\"):\n",
    "        pdf_path=os.path.join(pdf_dir,pdf_file)\n",
    "        document_text=extract_text_from_pdf(pdf_path)\n",
    "\n",
    "        #Create embedding for the document text\n",
    "        document_embedding=embedder.encode([document_text])\n",
    "\n",
    "        #Generate a UUID for the file\n",
    "        doc_id=str(uuid.uuid5(uuid.NAMESPACE_DNS,pdf_file))  #Generates a UUID based on file name\n",
    "\n",
    "        #Defining a PointStruct Object. It represent a point in the vector space that can be stored in the Qdrant database. we define three information. \n",
    "        #Id == Document id, Vector = the embedding which represents the document in vector space, Payload = information or metadata about the document\n",
    "        point = PointStruct(\n",
    "            id=doc_id,\n",
    "            vector=document_embedding[0].tolist(),\n",
    "            payload={\"document\":document_text,\"source\":pdf_file}\n",
    "        )\n",
    "\n",
    "        #Insert the document into Qdrant\n",
    "        qdrant.upsert(\n",
    "            collection_name=collection_name, points=[point],\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for Query Expansion\n",
    "query_expansion_pipeline=pipeline('text-generation',model='gpt2')\n",
    "\n",
    "def expand_query(query,max_length=50):\n",
    "    expanded_query=query_expansion_pipeline(query,max_length=max_length,num_return_sequences=1, pad_token_id=50256)[0]['generated_text']   # Pad token id specifies the id for the padding token. It marks the end of sequence. \n",
    "    return expanded_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retrievel of the Documents\n",
    "\n",
    "def retrieve_relevant_document(query, qdrant, collection_name,embedder, top_k=3):\n",
    "    expanded_query=expand_query(query)\n",
    "\n",
    "    #Create embedding for the expanded query\n",
    "    query_embedding=embedder.encode([expanded_query])\n",
    "\n",
    "    #Search in Qdrant for similar documents\n",
    "    search_result=qdrant.search(\n",
    "        collection_name=collection_name, query_vector=query_embedding[0].tolist(),\n",
    "        limit=top_k\n",
    "    )\n",
    "\n",
    "    #Extract the most relevant document and their source\n",
    "    retrieved_documents=[(result.payload['document'],result.payload['source']) for result in search_result]\n",
    "    return retrieved_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to Generate a Response\n",
    "\n",
    "tokenizer=GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model=GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "\n",
    "def generate_response(query,qdrant,collection_name,embedder, model, tokenizer):\n",
    "    retrieved_docs=retrieve_relevant_document(query,qdrant, collection_name,embedder)\n",
    "\n",
    "    #Concatenate the retrieved documents to form the context\n",
    "    context=\" \".join([doc[0] for doc in retrieved_docs])\n",
    "    sources= [doc[1] for doc in retrieved_docs]\n",
    "\n",
    "    #Prepare the input for the language model\n",
    "    input_text= f\"{context} [SEP] {qdrant}\"\n",
    "    inputs=tokenizer(input_text,return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "\n",
    "    #Generate Response\n",
    "    output=model.generate(**inputs,max_length=600, pad_token_id=tokenizer.eos_token_id)\n",
    "\n",
    "    #Decode the generated text\n",
    "    response=tokenizer.decode(output[0],skip_special_tokens=True)\n",
    "\n",
    "    return response, sources\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Response:: Margie’s Travel Presents… \n",
      "Dubai \n",
      " \n",
      " \n",
      "Dubai is the largest and most populous city in the United \n",
      "Arab Emirates. It is located on the southeast coast of the \n",
      "Persian Gulf and is the capital of the Emirate of Dubai, \n",
      "one of the seven emirates that make up the country. Abu \n",
      "Dhabi and Dubai are the only two emirates to have veto \n",
      "power over critical matters of national importance in the \n",
      "country's Federal Supreme Council. The city of Dubai is \n",
      "located on the emirate's northern coastline and heads the \n",
      "Dubai-Sharjah-Ajman metropolitan area. \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "Dubai Hotels \n",
      "Margie’s Travel offers the following accommodation \n",
      "options in Dubai: \n",
      "The Creek Hotel \n",
      "Friendly boutique hotel within the heart of the bustling \n",
      "Dubai Creek area. \n",
      "The Deira Hotel \n",
      "Family-run hotel in Dubai’s traditional commercial \n",
      "center. \n",
      "The Lost City Hotel \n",
      "Luxurious accommodation in Dubai, with onsite \n",
      "waterpark and aquarium. \n",
      " \n",
      " \n",
      " \n",
      "To book your trip to Dubai, visit www.margiestravel.com \n",
      " \n",
      "  \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "Wherever you want to go, Margie’s Travel can get you there! \n",
      "Margie’s Travel is a world-leading travel agency, combining international reach with local \n",
      "expertise. Just tell us where you want to go, and we can arrange: \n",
      "• Flights \n",
      "• Accommodation \n",
      "• Transfers \n",
      "• Visas \n",
      "• Currency Exchange \n",
      "• Excursions \n",
      " \n",
      "Where We Go \n",
      "While we can arrange travel to anywhere \n",
      "worldwide, we specialize in trips to: \n",
      "• Dubai \n",
      "• Las Vegas \n",
      "• London \n",
      "• New York \n",
      "• San Francisco \n",
      "Who We Are \n",
      "Margie’s Travel employs some of the \n",
      "best travel experts in the world. Our \n",
      "leadership team consists of: \n",
      "• Marjorie Long (CEO) \n",
      "• Logan Reid (CFO) \n",
      "• Emma Luffman (CTO) \n",
      "• Deepak Nadar (Strategic Director) \n",
      "• Dr. Naveen Kumar (CFO) \n",
      "• Dr. Naveen Kumar (CFO) \n",
      "• Dr. Naveen Kumar (CFO) \n",
      "• Dr. Naveen Kumar (CFO) \n",
      "• Dr. Naveen Kumar (CFO) \n",
      "• Dr. Naveen Kumar (CFO) \n",
      "• Dr. Naveen Kumar\n",
      "Sources:['Dubai Brochure.pdf', 'Margies Travel Company Info.pdf', 'Las Vegas Brochure.pdf']\n"
     ]
    }
   ],
   "source": [
    "query=input(\"How may I help you?\")\n",
    "response, sources=generate_response(query,qdrant,collection_name,embedder,model,tokenizer)\n",
    "\n",
    "print(f\"Generated Response:: {response}\")\n",
    "print(f\"Sources:{sources}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Advanced RAG Implementation using Query Expansion with Qdrant Vector db "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
