{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to Load pdf documents\n",
    "def load_pdf_doc(directory):\n",
    "    docs=[]\n",
    "    file_names=[] \n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('.pdf'):\n",
    "            file_path=os.path.join(directory,filename)\n",
    "            with open(file_path,'rb') as file:\n",
    "                reader=PyPDF2.PdfReader(file)\n",
    "                text=''\n",
    "                for page in range(len(reader.pages)):\n",
    "                    text+= reader.pages[page].extract_text()\n",
    "                docs.append(text)\n",
    "                file_names.append(filename)\n",
    "    return docs,file_names\n",
    "pdf_directory=r'brochures'\n",
    "docs, file_names=load_pdf_doc(pdf_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Intialize the Vectorization and fit the documents\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer=TfidfVectorizer()\n",
    "doc_vectors= vectorizer.fit_transform(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_relevent_doc(query, doc_vectors, vectorizer,docs,file_names):\n",
    "    query_vector=vectorizer.transform([query])\n",
    "    similarities=cosine_similarity(query_vector,doc_vectors).flatten()\n",
    "    most_similar_doc_index=np.argmax(similarities)\n",
    "    return docs[most_similar_doc_index], file_names[most_similar_doc_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Pre trained model and tokenizer\n",
    "\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved Document: Margie’s Travel Presents…  \n",
      "Las Vegas  \n",
      " Las Vegas, officially \n",
      "the City of Las Vegas \n",
      "and often known \n",
      "simply as Vegas, is the \n",
      "28th-most populated \n",
      "city in the United \n",
      "States, the most \n",
      "populated ci....\n",
      "\n",
      "Document Source:Las Vegas Brochure.pdf\n",
      "\n",
      "Generated Response:Margie’s Travel Presents…  \n",
      "Las Vegas  \n",
      " Las Vegas, officially \n",
      "the City of Las Vegas \n",
      "and often known \n",
      "simply as Vegas, is the \n",
      "28th-most populated \n",
      "city in the United \n",
      "States, the most \n",
      "populated city in the \n",
      "state of Nevada, and \n",
      "the county seat of \n",
      "Clark County. The city \n",
      "anchors the Las Vegas \n",
      "Valley me tropolitan \n",
      "area and is the largest \n",
      "city within the greater Mojave Desert. Las Vegas is an internationally renowned major resort city, \n",
      "known primarily for its gambling, shopping, fine dining, entertainment, and nightlife. The Las Vegas \n",
      "Valley as a whole ser ves as the leading financial, commercial, and cultural center for Nevada.  \n",
      "Las Vegas Hotels  \n",
      "Margie’s Travel offers the \n",
      "following hotels  in Las \n",
      "Vegas : \n",
      "The Volcano  Hotel  \n",
      "In the heart of The Strip. \n",
      "Stylish casino hotel with  \n",
      "live entertainment  and an \n",
      "extensive  pool area.  \n",
      "The Fountain  Hotel  \n",
      "Luxury  accommodation in  \n",
      "Las Vegas with a range of \n",
      "restaurants and cocktail \n",
      "bars \n",
      "The Canal  Hotel  \n",
      "An opulent Italian -themed  \n",
      "resort with luxurious suite \n",
      "accommodation.  \n",
      " \n",
      "To book your trip to Las Vegas, visit www.margiestravel.com  \n",
      " \n",
      " [SEP] hotels  \n",
      "Las Vegas  \n",
      "Las Vegas  \n",
      "Las Vegas  \n",
      "Las Vegas  \n",
      "Las Vegas  \n",
      "Las Vegas  \n",
      "Las Vegas  \n",
      "Las Vegas  \n",
      "Las Vegas  \n",
      "Las Vegas  \n",
      "Las Vegas  \n",
      "Las Vegas  \n",
      "Las Vegas  \n",
      "Las Vegas  \n",
      "Las Vegas  \n",
      "Las Vegas  \n",
      "Las Vegas  \n",
      "Las Vegas  \n",
      "Las Vegas  \n",
      "Las Vegas  \n",
      "Las Vegas  \n",
      "Las Vegas\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tokenizer =GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model=GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "\n",
    "def generate_response(query,context):\n",
    "#Combine the context and query into a single input for the model\n",
    "    input_text = f\"{context} [SEP] {query}\"\n",
    "    input_ids =tokenizer.encode(input_text, return_tensors='pt')\n",
    "\n",
    "#Generate the output\n",
    "    output=model.generate(input_ids, max_length=450, num_return_sequences=1)\n",
    "    response= tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    return response\n",
    "\n",
    "#RAG Pipeline\n",
    "\n",
    "def rag_pipeline(query):\n",
    "    #Step 1: Retrieving the most relevant document\n",
    "    context, file_name = retrieve_relevent_doc(query, doc_vectors,vectorizer, docs, file_names)\n",
    "    print(f\"Retrieved Document: {context[:200]}....\\n\")  # print first 200 characters of the document\n",
    "    print(f\"Document Source:{file_name}\\n\")\n",
    "\n",
    "    # Step 2: Generate a response using the retrieved document as context\n",
    "    response=generate_response(query,context)\n",
    "    return response\n",
    "\n",
    "query =input(\"Hi. I am your Travel assistant. How can I help you?\")\n",
    "response= rag_pipeline(query)\n",
    "print(f\"Generated Response:{response}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
